{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ded7ca94-4a8e-4f1e-b762-051ffe903b53",
   "metadata": {},
   "source": [
    "## Save in two formats\n",
    "- Save to data/raw/ as CSV and to data/processed/ as Parquet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc115436-5961-4c89-bd38-0cad030d9a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   date    20 non-null     datetime64[ns]\n",
      " 1   ticker  20 non-null     object        \n",
      " 2   price   20 non-null     float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(1)\n",
      "memory usage: 612.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv,dotenv_values\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from src.utils import *\n",
    "\n",
    "#generate data\n",
    "dates = pd.date_range('2024-01-01', periods=20, freq='D')\n",
    "df = pd.DataFrame({'date': dates, 'ticker': ['AAPL']*20, 'price': 150 + np.random.randn(20).cumsum()})\n",
    "df.head()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a609f44-39dd-4b24-9668-3a69c70dd45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved file to:  ../data/raw\n",
      "Successfully saved file to:  ../data/processed\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import os\n",
    "\n",
    "# save data\n",
    "fname_csv = get_filename(\"sample\",{},\"csv\")\n",
    "fname_parquet = get_filename(\"sample\",{},\"parquet\")\n",
    "write_df(df,False,\"csv\",fname_csv)\n",
    "write_df(df,True,\"parquet\",fname_parquet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0554b720-7275-4199-b4b8-e935fac69599",
   "metadata": {},
   "source": [
    "## Reload and Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5108584-26ea-432a-be04-10f4ee3e3160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV reload validation: {'Shape Validation': 'Passed', 'Data type validation': 'Failed'}\n",
      "Parquet reload validation: {'Shape Validation': 'Passed', 'Data type validation': 'Passed'}\n"
     ]
    }
   ],
   "source": [
    "# Reload data\n",
    "df_csv = read_df(False,\"csv\",fname_csv)\n",
    "df_parquet = read_df(True,\"parquet\",fname_parquet)\n",
    "\n",
    "# Validate\n",
    "def validate( df_reload, df_original ):\n",
    "    msgs = {\"Shape Validation\" : \"Passed\", \"Data type validation\" : \"Passed\"}\n",
    "    if( df_reload.shape != df_original.shape ):\n",
    "        msgs[\"Shape Validation\"] = \"Failed\"\n",
    "    for key in df_original.columns:\n",
    "        if( df_original[key].dtype != df_reload[key].dtype ):\n",
    "            msgs[\"Data type validation\"] = \"Failed\"\n",
    "    return msgs \n",
    "\n",
    "validation_csv = validate( df_csv, df )\n",
    "validation_parquet = validate( df_parquet, df )\n",
    "print( f\"CSV reload validation: {validation_csv}\")\n",
    "print( f\"Parquet reload validation: {validation_parquet}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
